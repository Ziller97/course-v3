{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "import scipy.io\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spectral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare PAVIA CENTRE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/home/zeefan/Repo/Pavia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(path/\"Pavia.mat\")\n",
    "data = data[\"pavia\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the PAVIA dataset, each pixel can be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2d = data.transpose(2,0,1).reshape(102,-1)\n",
    "new2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have reshaped our data to make each voxel a vector in the new array new2d, we can label each pixel.\n",
    "For the sake of clarity in our transformation, the pixel data[1, 2, 0] corresponds to the following pixel in the new array: new2d[0, (1*715 + 2)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[1,2,0])\n",
    "new2d[0,717]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we setup the labels using the given Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT = scipy.io.loadmat(path/\"Pavia_gt.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = GT[\"pavia_gt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know what the classes are as they are given on the website we obtained the dataset from. The classes are defined by integers, and the integers are populated on a 2d matrix to reference the index of each object:\n",
    "##### 1 = Water\n",
    "##### 2 = Trees\n",
    "##### 3 = Asphalt\n",
    "##### 4 = Self-Blocking Bricks\n",
    "##### 5 = Bitumen\n",
    "##### 6 = Tiles\n",
    "##### 7 = Shadows\n",
    "##### 8 = Meadows\n",
    "##### 9 = Bare Soil\n",
    "Now we can collect the indices of pixels in their respective classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = np.where(truth==1)\n",
    "lim = len(water[0])\n",
    "x = 0\n",
    "waterIndex=['water']\n",
    "while x<lim:\n",
    "    waterIndex.append((water[0][x],water[1][x]))\n",
    "    x=x+1\n",
    "    \n",
    "trees = np.where(truth==2)\n",
    "lim = len(trees[0])\n",
    "x=0\n",
    "treesIndex=[]\n",
    "while x<lim:\n",
    "    treesIndex.append((trees[0][x],trees[1][x]))\n",
    "    x=x+1\n",
    "    \n",
    "asphalt = np.where(truth==3)\n",
    "lim = len(asphalt[0])\n",
    "x=0\n",
    "asphaltIndex=['asphalt']\n",
    "while x<lim:\n",
    "    asphaltIndex.append((asphalt[0][x],asphalt[1][x]))\n",
    "    x=x+1\n",
    "    \n",
    "bricks = np.where(truth==4)\n",
    "lim = len(bricks[0])\n",
    "x=0\n",
    "bricksIndex=['bricks']\n",
    "while x<lim:\n",
    "    bricksIndex.append((bricks[0][x],bricks[1][x]))\n",
    "    x=x+1\n",
    "    \n",
    "bitumen = np.where(truth==5)\n",
    "lim = len(bitumen[0])\n",
    "x=0\n",
    "bitumenIndex=['bitumen']\n",
    "while x<lim:\n",
    "    bitumenIndex.append((bitumen[0][x],bitumen[1][x]))\n",
    "    x=x+1\n",
    "    \n",
    "tiles = np.where(truth==6)\n",
    "lim = len(tiles[0])\n",
    "x=0\n",
    "tilesIndex=['tiles']\n",
    "while x<lim:\n",
    "    tilesIndex.append((tiles[0][x],tiles[1][x]))\n",
    "    x=x+1\n",
    "    \n",
    "shadows = np.where(truth==6)\n",
    "lim = len(shadows[0])\n",
    "x=0\n",
    "shadowsIndex=['shadows']\n",
    "while x<lim:\n",
    "    shadowsIndex.append((shadows[0][x],shadows[1][x]))\n",
    "    x=x+1\n",
    "    \n",
    "meadows = np.where(truth==7)\n",
    "lim = len(meadows[0])\n",
    "x=0\n",
    "meadowsIndex=['meadows']\n",
    "while x<lim:\n",
    "    meadowsIndex.append((meadows[0][x],meadows[1][x]))\n",
    "    x=x+1\n",
    "    \n",
    "soil = np.where(truth==7)\n",
    "lim = len(soil[0])\n",
    "x=0\n",
    "soilIndex=['soil']\n",
    "while x<lim:\n",
    "    soilIndex.append((soil[0][x],soil[1][x]))\n",
    "    x=x+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the column vectors (voxels) into the appropriate groups of classes. Remember, the ground truth index (x,y) corresponds to the ( x * data.shape[1] + y ) column of the voxel array (new2d).\n",
    "### SETUP INDICES TO SORT THROUGH THE NEW2D ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaled = (255.0 / data.max() * (data - data.min())).astype(np.uint8)\n",
    "help(Image.fromarray)\n",
    "# im = Image.fromarray(rescaled)\n",
    "# im.save('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break the tif dataset into pieces, and use ground truth to label each piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spectral import *\n",
    "#from spectral import *\n",
    "import gdal\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "import sys\n",
    "#from osgeo import gdal_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/zeefan/Repo/Pavia')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2tif = Path('/home/zeefan/Repo/Pavia')\n",
    "path2tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open('/home/zeefan/Repo/Pavia/Pablo.tif')\n",
    "#gdal_translate -of GTiff -co \n",
    "# rasterArray = gdal_array.LoadFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myarray = np.array(ds.GetRasterBand(1).ReadAsArray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myarray[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out the format the dataset needs to be in to input it into cnn_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=224, bs=bs\n",
    "#                                 ).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(DataBunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
